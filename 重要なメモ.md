1. **ディフュージョンサンプラーを有効にすると出力が壊れます:**

*残念ながら、ハードウェアによっては、ディフュージョンサンプラーが機能しない可能性があります。この問題は私の管理外で、異なるハードウェアが浮動小数点演算を処理する方法に関連しているようです。A40、V100、Google Colabの T4 GPUでは機能することを確認していますが、同じGPUを持っていても動作を保証することはできません。CPUを使用しても同じ問題が起こります。これは元のStyleTTS2で深刻な問題でしたが、私が追加したさまざまなサンプリング方法を使うことで、品質への影響を最小限に抑えつつ、ディフュージョンサンプラーを無効にすることができます。*

2. **提供されたサンプルの品質を再現できない、または一貫して良い結果が得られない:**

*可制御性には代償がかかり、それはユーザビリティの低下です。特に、本質的に非決定的なモジュールで構成されたネットワークの場合に当てはまります。システムはスタイルベクトルの変動に非常に敏感です。ただし、推論パラメーターを慎重に調整し、試行錯誤すれば、ほとんど常に最も印象的な自然な表現を達成できると確信しています。また、一部のスピーカーは特定の感情を一貫して処理できない可能性があるため、別のスピーカーから新しい感情を作り出すことができます。Gradioスペースや推論ノートブックでの詳しい使用方法を説明しています。*

3. **[RuntimeError: The size of tensor a (512) must match the size of tensor b (some number) at non-singleton dimension 3]:**

*入力が1回の推論に対して長すぎます。Longform推論機能を使用してください。これは特に、Tsumugi(仮称)チェックポイントでは問題になります。mLSTMレイヤーのコンテキスト長が512に制限されているため、Longform機能を使用しない限り、約10秒以上の音声を生成できません。ただし、他のチェックポイントではこれは問題にはなりません。Longform アルゴリズムのおかげで、出力の長さに理論的な制限はありません。*

4. **短い入力が印象的ではない:**

*2で述べたことがすべて当てはまります。スタイルベクトルが適切かどうかを確認してください。ただし、一般的に非常に短い入力の使用は推奨されません。*

5. **2段階目の訓練でNaNが発生:**

*グラジエントが爆発しているのかもしれません。クリッピングを試すか、バッチサイズが大すぎる可能性があります。それでも解決しない場合は、オリジナルのDPスクリプトを使って最初の数エポックを事前訓練することをお勧めします。または、完全にDPを使用してください。*

6. **Kotodam inferenceにあるスピーカーさんの名前について:**

   
*全部ランダムでマッピングされていますので、実際の人物やロールなどとは一切関係していません。*